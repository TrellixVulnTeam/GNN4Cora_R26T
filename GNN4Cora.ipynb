{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9089eb",
   "metadata": {},
   "source": [
    "# Graph Neural Networks for Cora Dataset\n",
    "This file briefly explains **how to set up the environment and perform a simple run using the submitted code**. For detailed command-line arguments explanations, check `README.md`. For more details on theory and experiment, check `Report.pdf`. To see a complete setup-run procedure, check https://drive.google.com/file/d/1ZyLTXgGcWOLmPE0lKd1rb3FqZTy6wmnO/view?usp=sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caf19d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This file relates to a course project which aims to train and test multi-class classifiers on the [Cora Dataset](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz). Here, we mainly focus on using GNNs (Graph Neural Networks) and compare different ideas of designing the network structure. We implement three GNNs, namely [GCN](https://arxiv.org/pdf/1609.02907.pdf), [GAT](https://arxiv.org/pdf/1710.10903.pdf) and [GaAN](https://arxiv.org/pdf/1803.07294.pdf).\n",
    "\n",
    "The model implementation uses [PyTorch](https://pytorch.org/) and [Deep Graph Library](https://www.dgl.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455e535",
   "metadata": {},
   "source": [
    "## Note\n",
    "For reference, our python version and GPU status are listed below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cee303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Fri_Dec_17_18:28:54_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.6, V11.6.55\n",
      "Build cuda_11.6.r11.6/compiler.30794723_0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13afce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 27 18:14:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.77       Driver Version: 512.77       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   36C    P8     9W /  N/A |    153MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1300    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     19204    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     42924    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     44108    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     48996    C+G   ...2gh52qy24etm\\Nahimic3.exe    N/A      |\n",
      "|    0   N/A  N/A     54368    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     55080    C+G   ...210.53\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     55360    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91165247",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "The required python packages are listed below:\n",
    "- [Pytorch](https://pytorch.org/get-started/locally/) installed with CUDA support\n",
    "- [DGL (Deep Graph Library)](https://www.dgl.ai/pages/start.html) installed with CUDA support\n",
    "- numpy\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9d258",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885cb5f7",
   "metadata": {},
   "source": [
    "### 1.1 Get Project Code\n",
    "If this file is opened in the code repository, then proceed to the next step. If this file is being examined in [**Google Colab**](https://colab.research.google.com/?utm_source=scs-index), then uncomment the following code block and run it to clone the code repository (The repository is currently private and will be opened publicly after the project submission deadline. If there is any problem, please send an email to petershen815@126.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeca4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/WingsUpete/GNN4Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b094c4eb",
   "metadata": {},
   "source": [
    "### 1.2 Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f6d41",
   "metadata": {},
   "source": [
    "Install basic packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15d6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (1.22.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983ac3a",
   "metadata": {},
   "source": [
    "Install PyTorch and DGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1658955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\envs\\ida\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\envs\\ida\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: torchaudio in d:\\anaconda3\\envs\\ida\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (1.22.1)\n",
      "Requirement already satisfied: requests in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (9.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests->torchvision) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ade003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
      "Requirement already satisfied: dgl-cu113 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (0.7.2)\n",
      "Requirement already satisfied: dglgo in d:\\anaconda3\\envs\\ida\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from dgl-cu113) (1.7.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from dgl-cu113) (2.27.1)\n",
      "Requirement already satisfied: networkx>=2.1 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from dgl-cu113) (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from dgl-cu113) (1.22.1)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.20 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (0.17.21)\n",
      "Requirement already satisfied: autopep8>=1.6.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=1.9.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (1.9.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (6.0)\n",
      "Requirement already satisfied: typer>=0.4.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (0.4.1)\n",
      "Requirement already satisfied: isort>=5.10.1 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (5.10.1)\n",
      "Requirement already satisfied: numpydoc>=1.1.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from dglgo) (1.3.1)\n",
      "Requirement already satisfied: toml in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from autopep8>=1.6.0->dglgo) (0.10.2)\n",
      "Requirement already satisfied: pycodestyle>=2.8.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from autopep8>=1.6.0->dglgo) (2.8.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
      "Requirement already satisfied: sphinx>=3.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from numpydoc>=1.1.0->dglgo) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from pydantic>=1.9.0->dglgo) (4.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from requests>=2.19.0->dgl-cu113) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->dgl-cu113) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->dgl-cu113) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->dgl-cu113) (2.0.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (21.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
      "Requirement already satisfied: colorama>=0.3.5 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.4.4)\n",
      "Requirement already satisfied: babel>=1.3 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.10.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
      "Requirement already satisfied: Pygments>=2.0 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.12.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.11.4)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n",
      "Requirement already satisfied: imagesize in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from babel>=1.3->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2021.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda3\\envs\\ida\\lib\\site-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\peter\\appdata\\roaming\\python\\python39\\site-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.0.6)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b4c7e",
   "metadata": {},
   "source": [
    "### 1.3 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d363e5",
   "metadata": {},
   "source": [
    "Move to the root directory if operating in **Google Colab** (if not, ignore the following line of code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cebfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /content/GNN4Cora/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac4c12",
   "metadata": {},
   "source": [
    "Prepare and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543fc27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\tmpStorage\\IDA\\Project\\code\\GNN4Cora\\preprocess\n",
      "> [CoraPreprocessor:init] CoraPreProcessor successfully initialized.\n",
      "> [CoraPreprocessor:construct_pub_dict] Processing ../data/cora/cora.content\n",
      "> [CoraPreprocessor:construct_pub_dict] Processing ../data/cora/cora.cites\n",
      "> [CoraPreprocessor:construct_pub_dict] Collecting components to construct the publication dictionary...\n",
      "> [CoraPreprocessor:construct_pub_dict] Publication dictionary saved to ../data/cora/meta.json\n",
      "> [CoraPreprocessor:construct_graph] Constructing DGLGraph...\n",
      "> [CoraPreprocessor:construct_graph] DGLGraph saved to ../data/cora/cora.dgl\n",
      "D:\\tmpStorage\\IDA\\Project\\code\\GNN4Cora\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('data'):\n",
    "    print('> Creating \"data\" directory.')\n",
    "    os.mkdir('data')\n",
    "%cd preprocess/\n",
    "!python CoraPreprocessor.py -dr ../data/cora/\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685bc269",
   "metadata": {},
   "source": [
    "## 2. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762b993",
   "metadata": {},
   "source": [
    "As an example, we will show how to train and evaluate GaAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "510b5620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Seed: 6666666\n",
      "> device: cuda:0\n",
      "> Loading DataSet from data/cora/\n",
      "> Data sent to cuda:0\n",
      "> view: both\n",
      "> num_nodes: 2708, num_edges: [10556]\n",
      "> num_feats: 1433, num_classes: 7\n",
      "> num_samples: training = 270, validation = 812, test = 1626\n",
      "> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}\n",
      "> Initializing the Training Model: GaAN\n",
      "> Model Structure:\n",
      "GaAN(\n",
      "  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)\n",
      "  (embed_fc): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tran_fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n",
      "> Model sent to cuda:0\n",
      "> Constructing the Optimizer: ADAM\n",
      "> Using CrossEntropyLoss as the Loss Function.\n",
      "\n",
      "learning_rate = 0.01, epochs = 75\n",
      "eval_freq = 5, optimizer = ADAM\n",
      "\n",
      "Start Training!\n",
      "------------------------------------------------------------------------\n",
      "Training Round 1: loss = 2.223528, time_cost = 4.1979 sec, acc = 17.0370%\n",
      "Training Round 2: loss = 1.416553, time_cost = 0.4652 sec, acc = 45.9259%\n",
      "Training Round 3: loss = 0.809024, time_cost = 0.5017 sec, acc = 81.1111%\n",
      "Training Round 4: loss = 0.350865, time_cost = 0.4840 sec, acc = 97.4074%\n",
      "Training Round 5: loss = 0.126183, time_cost = 0.5012 sec, acc = 98.8889%\n",
      "!!! Evaluation: valid_acc = 72.6601%, test_acc = 74.1082%\n",
      "Training Round 6: loss = 0.040574, time_cost = 0.5338 sec, acc = 99.6296%\n",
      "Training Round 7: loss = 0.013757, time_cost = 0.4602 sec, acc = 99.6296%\n",
      "Training Round 8: loss = 0.006113, time_cost = 0.4932 sec, acc = 99.6296%\n",
      "Training Round 9: loss = 0.006870, time_cost = 0.4961 sec, acc = 99.6296%\n",
      "Training Round 10: loss = 0.002176, time_cost = 0.4764 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 77.5862%, test_acc = 79.4588%\n",
      "Training Round 11: loss = 0.001610, time_cost = 0.4713 sec, acc = 100.0000%\n",
      "Training Round 12: loss = 0.001822, time_cost = 0.4579 sec, acc = 100.0000%\n",
      "Training Round 13: loss = 0.001648, time_cost = 0.5568 sec, acc = 100.0000%\n",
      "Training Round 14: loss = 0.001144, time_cost = 0.5029 sec, acc = 100.0000%\n",
      "Training Round 15: loss = 0.001322, time_cost = 0.4706 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 78.6946%, test_acc = 78.4748%\n",
      "Model: model_save/20220527_21_36_39.pth has been saved since it achieves higher validation accuracy.\n",
      "Training Round 16: loss = 0.001828, time_cost = 0.4758 sec, acc = 100.0000%\n",
      "Training Round 17: loss = 0.002809, time_cost = 0.4861 sec, acc = 100.0000%\n",
      "Training Round 18: loss = 0.004048, time_cost = 0.5043 sec, acc = 100.0000%\n",
      "Training Round 19: loss = 0.006842, time_cost = 0.4736 sec, acc = 100.0000%\n",
      "Training Round 20: loss = 0.011448, time_cost = 0.4677 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 80.4187%, test_acc = 80.6888%\n",
      "Model: model_save/20220527_21_36_39.pth has been saved since it achieves higher validation accuracy.\n",
      "Training Round 21: loss = 0.016516, time_cost = 0.4746 sec, acc = 100.0000%\n",
      "Training Round 22: loss = 0.021991, time_cost = 0.4866 sec, acc = 100.0000%\n",
      "Training Round 23: loss = 0.025812, time_cost = 0.4650 sec, acc = 100.0000%\n",
      "Training Round 24: loss = 0.027594, time_cost = 0.4769 sec, acc = 100.0000%\n",
      "Training Round 25: loss = 0.027153, time_cost = 0.4727 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 80.9113%, test_acc = 81.4268%\n",
      "Model: model_save/20220527_21_36_39.pth has been saved since it achieves higher validation accuracy.\n",
      "Training Round 26: loss = 0.025310, time_cost = 0.4758 sec, acc = 100.0000%\n",
      "Training Round 27: loss = 0.023722, time_cost = 0.4549 sec, acc = 100.0000%\n",
      "Training Round 28: loss = 0.021004, time_cost = 0.4740 sec, acc = 100.0000%\n",
      "Training Round 29: loss = 0.019051, time_cost = 0.4777 sec, acc = 100.0000%\n",
      "Training Round 30: loss = 0.018678, time_cost = 0.4834 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.8966%, test_acc = 83.2718%\n",
      "Model: model_save/20220527_21_36_39.pth has been saved since it achieves higher validation accuracy.\n",
      "Training Round 31: loss = 0.017271, time_cost = 0.4731 sec, acc = 100.0000%\n",
      "Training Round 32: loss = 0.016801, time_cost = 0.4746 sec, acc = 100.0000%\n",
      "Training Round 33: loss = 0.014973, time_cost = 0.4729 sec, acc = 100.0000%\n",
      "Training Round 34: loss = 0.015890, time_cost = 0.5097 sec, acc = 100.0000%\n",
      "Training Round 35: loss = 0.015557, time_cost = 0.4804 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 82.2660%, test_acc = 83.5793%\n",
      "Model: model_save/20220527_21_36_39.pth has been saved since it achieves higher validation accuracy.\n",
      "Training Round 36: loss = 0.016483, time_cost = 0.4772 sec, acc = 100.0000%\n",
      "Training Round 37: loss = 0.016760, time_cost = 0.4799 sec, acc = 100.0000%\n",
      "Training Round 38: loss = 0.018004, time_cost = 0.5025 sec, acc = 100.0000%\n",
      "Training Round 39: loss = 0.017008, time_cost = 0.4649 sec, acc = 100.0000%\n",
      "Training Round 40: loss = 0.019373, time_cost = 0.4816 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.5271%, test_acc = 83.2718%\n",
      "Training Round 41: loss = 0.017979, time_cost = 0.4766 sec, acc = 100.0000%\n",
      "Training Round 42: loss = 0.017515, time_cost = 0.5031 sec, acc = 100.0000%\n",
      "Training Round 43: loss = 0.017098, time_cost = 0.4809 sec, acc = 100.0000%\n",
      "Training Round 44: loss = 0.015986, time_cost = 0.4677 sec, acc = 100.0000%\n",
      "Training Round 45: loss = 0.014242, time_cost = 0.4733 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.0345%, test_acc = 83.7638%\n",
      "Training Round 46: loss = 0.014852, time_cost = 0.5120 sec, acc = 100.0000%\n",
      "Training Round 47: loss = 0.015788, time_cost = 0.4799 sec, acc = 100.0000%\n",
      "Training Round 48: loss = 0.014898, time_cost = 0.5028 sec, acc = 100.0000%\n",
      "Training Round 49: loss = 0.014766, time_cost = 0.4819 sec, acc = 100.0000%\n",
      "Training Round 50: loss = 0.015804, time_cost = 0.4853 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.2808%, test_acc = 83.8253%\n",
      "Training Round 51: loss = 0.015780, time_cost = 0.5086 sec, acc = 100.0000%\n",
      "Training Round 52: loss = 0.015793, time_cost = 0.4713 sec, acc = 100.0000%\n",
      "Training Round 53: loss = 0.014382, time_cost = 0.4807 sec, acc = 100.0000%\n",
      "Training Round 54: loss = 0.015295, time_cost = 0.4682 sec, acc = 100.0000%\n",
      "Training Round 55: loss = 0.014768, time_cost = 0.5012 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.2808%, test_acc = 83.3333%\n",
      "Training Round 56: loss = 0.016092, time_cost = 0.4644 sec, acc = 100.0000%\n",
      "Training Round 57: loss = 0.014655, time_cost = 0.4838 sec, acc = 100.0000%\n",
      "Training Round 58: loss = 0.013945, time_cost = 0.4640 sec, acc = 100.0000%\n",
      "Training Round 59: loss = 0.013231, time_cost = 0.4752 sec, acc = 100.0000%\n",
      "Training Round 60: loss = 0.014125, time_cost = 0.4818 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.0345%, test_acc = 83.4563%\n",
      "Training Round 61: loss = 0.014111, time_cost = 0.4823 sec, acc = 100.0000%\n",
      "Training Round 62: loss = 0.013373, time_cost = 0.4896 sec, acc = 100.0000%\n",
      "Training Round 63: loss = 0.013560, time_cost = 0.4709 sec, acc = 100.0000%\n",
      "Training Round 64: loss = 0.012845, time_cost = 0.4639 sec, acc = 100.0000%\n",
      "Training Round 65: loss = 0.013463, time_cost = 0.4666 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 79.9261%, test_acc = 83.3333%\n",
      "Training Round 66: loss = 0.014458, time_cost = 0.5155 sec, acc = 100.0000%\n",
      "Training Round 67: loss = 0.014424, time_cost = 0.4767 sec, acc = 100.0000%\n",
      "Training Round 68: loss = 0.014106, time_cost = 0.4634 sec, acc = 100.0000%\n",
      "Training Round 69: loss = 0.014316, time_cost = 0.4763 sec, acc = 100.0000%\n",
      "Training Round 70: loss = 0.014298, time_cost = 0.4819 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.6502%, test_acc = 83.2718%\n",
      "Training Round 71: loss = 0.014163, time_cost = 0.4680 sec, acc = 100.0000%\n",
      "Training Round 72: loss = 0.012739, time_cost = 0.5115 sec, acc = 100.0000%\n",
      "Training Round 73: loss = 0.012441, time_cost = 0.4575 sec, acc = 100.0000%\n",
      "Training Round 74: loss = 0.013630, time_cost = 0.4650 sec, acc = 100.0000%\n",
      "Training Round 75: loss = 0.012812, time_cost = 0.4650 sec, acc = 100.0000%\n",
      "!!! Evaluation: valid_acc = 81.6502%, test_acc = 83.0873%\n",
      "> Training finished.\n",
      "\n",
      "> device: cuda:0\n",
      "> Loading DataSet from data/cora/\n",
      "> Data sent to cuda:0\n",
      "> view: both\n",
      "> num_nodes: 2708, num_edges: [10556]\n",
      "> num_feats: 1433, num_classes: 7\n",
      "> num_samples: training = 270, validation = 812, test = 1626\n",
      "> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}\n",
      "> Loading model_save/20220527_21_36_39.pth\n",
      "> Model Structure:\n",
      "GaAN(\n",
      "  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)\n",
      "  (embed_fc): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tran_fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n",
      "> Model sent to cuda:0\n",
      "> Evaluation Results: valid_acc = 81.8966%, test_acc = 83.3948%\n",
      "> Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "!python Trainer.py -dr data/cora/ -gid 0 -m trainNeval -net GaAN -tag GaAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68baf53",
   "metadata": {},
   "source": [
    "We specify the data folder as \"data/cora/\", GPU id as 0. \"-m\" specifies the training mode as \"trainNeval\", which means to evaluate the model right after training. \"-tag\" provides a tag string to the saved log file. The outputs are also saved to a log file so later on we can check it.\n",
    "\n",
    "To evaluate a trained model, pass the \".pth\" file to the trainer as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59cfeed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Seed: 6666666\n",
      "> device: cuda:0\n",
      "> Loading DataSet from data/cora/\n",
      "> Data sent to cuda:0\n",
      "> view: both\n",
      "> num_nodes: 2708, num_edges: [10556]\n",
      "> num_feats: 1433, num_classes: 7\n",
      "> num_samples: training = 270, validation = 812, test = 1626\n",
      "> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}\n",
      "> Loading records/models/20220527_21_36_39.pth\n",
      "> Model Structure:\n",
      "GaAN(\n",
      "  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)\n",
      "  (embed_fc): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): MultiHeadCGaANLayer(\n",
      "        (cGaANs): ModuleList(\n",
      "          (0): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (1): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "          (2): CGaANLayer(\n",
      "            (Wa): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (att_out_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (att_out_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_l): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_m): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (gate_fc_r): Linear(in_features=128, out_features=1, bias=False)\n",
      "            (Wgm): Linear(in_features=128, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tran_fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n",
      "> Model sent to cuda:0\n",
      "> Evaluation Results: valid_acc = 81.8966%, test_acc = 83.5178%\n",
      "> Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "!python Trainer.py -dr data/cora/ -gid 0 -m eval -e records/models/20220527_21_36_39.pth -tag GaAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759bdc4",
   "metadata": {},
   "source": [
    "The results might vary due to the randomness of dataset splitting (although a seed value is used, strangely).\n",
    "\n",
    "To examine the training procedure as a figure, we plot the loss curve as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72aa020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\tmpStorage\\IDA\\Project\\code\\GNN4Cora\\postprocess\n",
      "Analyzing log file: ../records/logs/GaAN_trainNeval_20220527_21_36_39.log\n",
      "Average train time: 0.5314 sec\n",
      "Plotting loss curve.\n",
      "Loss curve saved to ./GaAN_trainNeval_20220527_21_36_39.png\n",
      "All analysis tasks finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\tmpStorage\\IDA\\Project\\code\\GNN4Cora\n"
     ]
    }
   ],
   "source": [
    "%cd postprocess/\n",
    "!python LossCurveRenderer.py -i ../records/logs/GaAN_trainNeval_20220527_21_36_39.log -o ./\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename='GaAN_trainNeval_20220527_21_36_39.png'))\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832dbc8",
   "metadata": {},
   "source": [
    "We can see that the loss of the implemented GaAN model quickly decreased and converged in less than 10 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ida",
   "language": "python",
   "name": "ida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}