> Seed: 6666666
> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: both
> num_nodes: 2708, num_edges: [10556]
> num_feats: 1433, num_classes: 7
> num_samples: training = 270, validation = 812, test = 1626
> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}
> Initializing the Training Model: MLP
> Model Structure:
CMLP(
  (layers): Sequential(
    (0): Linear(in_features=1433, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=128, bias=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=7, bias=True)
    (7): ReLU()
  )
)
> Model sent to cuda:0
> Constructing the Optimizer: ADAM
> Using CrossEntropyLoss as the Loss Function.

learning_rate = 0.01, epochs = 75
eval_freq = 5, optimizer = ADAM

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 1.882530, time_cost = 1.4350 sec, acc = 30.0000%
Training Round 2: loss = 1.744208, time_cost = 0.0040 sec, acc = 29.2593%
Training Round 3: loss = 1.463148, time_cost = 0.0050 sec, acc = 45.5556%
Training Round 4: loss = 1.254763, time_cost = 0.0077 sec, acc = 68.1481%
Training Round 5: loss = 0.957066, time_cost = 0.0050 sec, acc = 76.6667%
!!! Evaluation: valid_acc = 48.1527%, test_acc = 47.1095%
Training Round 6: loss = 0.707936, time_cost = 0.0037 sec, acc = 78.5185%
Training Round 7: loss = 0.566623, time_cost = 0.0040 sec, acc = 80.3704%
Training Round 8: loss = 0.449853, time_cost = 0.0050 sec, acc = 85.9259%
Training Round 9: loss = 0.343904, time_cost = 0.0046 sec, acc = 91.8518%
Training Round 10: loss = 0.269230, time_cost = 0.0041 sec, acc = 91.8518%
!!! Evaluation: valid_acc = 60.4680%, test_acc = 61.5006%
Training Round 11: loss = 0.167894, time_cost = 0.0060 sec, acc = 93.7037%
Training Round 12: loss = 0.112907, time_cost = 0.0041 sec, acc = 99.6296%
Training Round 13: loss = 0.083503, time_cost = 0.0040 sec, acc = 99.2593%
Training Round 14: loss = 0.035619, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 15: loss = 0.023001, time_cost = 0.0041 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 59.6059%, test_acc = 63.2226%
Model: model_save/20220527_21_54_53.pth has been saved since it achieves higher validation accuracy.
Training Round 16: loss = 0.018194, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 17: loss = 0.014055, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 18: loss = 0.012008, time_cost = 0.0056 sec, acc = 100.0000%
Training Round 19: loss = 0.014755, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 20: loss = 0.021095, time_cost = 0.0040 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 62.6847%, test_acc = 63.4686%
Model: model_save/20220527_21_54_53.pth has been saved since it achieves higher validation accuracy.
Training Round 21: loss = 0.027745, time_cost = 0.0070 sec, acc = 100.0000%
Training Round 22: loss = 0.034108, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 23: loss = 0.040969, time_cost = 0.0064 sec, acc = 100.0000%
Training Round 24: loss = 0.048114, time_cost = 0.0047 sec, acc = 100.0000%
Training Round 25: loss = 0.052665, time_cost = 0.0040 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 62.5616%, test_acc = 64.7601%
Training Round 26: loss = 0.055722, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 27: loss = 0.055842, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 28: loss = 0.054425, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 29: loss = 0.052957, time_cost = 0.0056 sec, acc = 100.0000%
Training Round 30: loss = 0.049738, time_cost = 0.0050 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.3005%, test_acc = 66.1747%
Model: model_save/20220527_21_54_53.pth has been saved since it achieves higher validation accuracy.
Training Round 31: loss = 0.047222, time_cost = 0.0058 sec, acc = 100.0000%
Training Round 32: loss = 0.044768, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 33: loss = 0.042061, time_cost = 0.0052 sec, acc = 100.0000%
Training Round 34: loss = 0.040189, time_cost = 0.0054 sec, acc = 100.0000%
Training Round 35: loss = 0.038970, time_cost = 0.0050 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 64.0394%, test_acc = 65.9902%
Model: model_save/20220527_21_54_53.pth has been saved since it achieves higher validation accuracy.
Training Round 36: loss = 0.038713, time_cost = 0.0051 sec, acc = 100.0000%
Training Round 37: loss = 0.039276, time_cost = 0.0060 sec, acc = 100.0000%
Training Round 38: loss = 0.039726, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 39: loss = 0.040121, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 40: loss = 0.040492, time_cost = 0.0050 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 62.9310%, test_acc = 65.0061%
Training Round 41: loss = 0.040473, time_cost = 0.0045 sec, acc = 100.0000%
Training Round 42: loss = 0.040287, time_cost = 0.0065 sec, acc = 100.0000%
Training Round 43: loss = 0.039814, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 44: loss = 0.039088, time_cost = 0.0056 sec, acc = 100.0000%
Training Round 45: loss = 0.038619, time_cost = 0.0040 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.4236%, test_acc = 65.2522%
Training Round 46: loss = 0.038210, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 47: loss = 0.037853, time_cost = 0.0058 sec, acc = 100.0000%
Training Round 48: loss = 0.037805, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 49: loss = 0.037773, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 50: loss = 0.037870, time_cost = 0.0047 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.6699%, test_acc = 66.0517%
Training Round 51: loss = 0.038010, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 52: loss = 0.038039, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 53: loss = 0.038050, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 54: loss = 0.037898, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 55: loss = 0.037659, time_cost = 0.0060 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 64.0394%, test_acc = 66.1747%
Training Round 56: loss = 0.037417, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 57: loss = 0.037179, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 58: loss = 0.037016, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 59: loss = 0.036882, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 60: loss = 0.036880, time_cost = 0.0050 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.7931%, test_acc = 65.6827%
Training Round 61: loss = 0.036941, time_cost = 0.0071 sec, acc = 100.0000%
Training Round 62: loss = 0.037040, time_cost = 0.0040 sec, acc = 100.0000%
Training Round 63: loss = 0.037152, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 64: loss = 0.037200, time_cost = 0.0048 sec, acc = 100.0000%
Training Round 65: loss = 0.037219, time_cost = 0.0040 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.7931%, test_acc = 65.5597%
Training Round 66: loss = 0.037162, time_cost = 0.0046 sec, acc = 100.0000%
Training Round 67: loss = 0.037032, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 68: loss = 0.036863, time_cost = 0.0050 sec, acc = 100.0000%
Training Round 69: loss = 0.036722, time_cost = 0.0049 sec, acc = 100.0000%
Training Round 70: loss = 0.036611, time_cost = 0.0042 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.5468%, test_acc = 65.4367%
Training Round 71: loss = 0.036537, time_cost = 0.0043 sec, acc = 100.0000%
Training Round 72: loss = 0.036508, time_cost = 0.0049 sec, acc = 100.0000%
Training Round 73: loss = 0.036528, time_cost = 0.0063 sec, acc = 100.0000%
Training Round 74: loss = 0.036597, time_cost = 0.0051 sec, acc = 100.0000%
Training Round 75: loss = 0.036677, time_cost = 0.0047 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.9163%, test_acc = 65.4982%
> Training finished.

> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: both
> num_nodes: 2708, num_edges: [10556]
> num_feats: 1433, num_classes: 7
> num_samples: training = 270, validation = 812, test = 1626
> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}
> Loading model_save/20220527_21_54_53.pth
> Model Structure:
CMLP(
  (layers): Sequential(
    (0): Linear(in_features=1433, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=128, bias=True)
    (5): ReLU()
    (6): Linear(in_features=128, out_features=7, bias=True)
    (7): ReLU()
  )
)
> Model sent to cuda:0
> Evaluation Results: valid_acc = 64.0394%, test_acc = 65.9287%
> Evaluation finished.
