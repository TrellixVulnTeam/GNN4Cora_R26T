> Seed: 6666666
> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: both
> num_nodes: 2708, num_edges: [10556]
> num_feats: 1433, num_classes: 7
> num_samples: training = 140, validation = 500, test = 1000
> train_set_imbalance: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20}
> Initializing the Training Model: GCN
> Model Structure:
GCN(
  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)
  (embed_fc): Linear(in_features=128, out_features=128, bias=False)
  (layers): ModuleList(
    (0): ModuleList(
      (0): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
      (1): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
    )
  )
  (tran_fc): Linear(in_features=256, out_features=7, bias=True)
)
> Model sent to cuda:0
> Constructing the Optimizer: ADAM
> Using CrossEntropyLoss as the Loss Function.

learning_rate = 0.01, epochs = 75
eval_freq = 5, optimizer = ADAM

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 2.220989, time_cost = 1.7151 sec, acc = 8.5714%
Training Round 2: loss = 0.990114, time_cost = 0.0691 sec, acc = 70.0000%
Training Round 3: loss = 0.367724, time_cost = 0.0678 sec, acc = 92.8571%
Training Round 4: loss = 0.118106, time_cost = 0.0680 sec, acc = 100.0000%
Training Round 5: loss = 0.054526, time_cost = 0.0804 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.0000%, test_acc = 67.1000%
Training Round 6: loss = 0.029607, time_cost = 0.0807 sec, acc = 100.0000%
Training Round 7: loss = 0.014686, time_cost = 0.0731 sec, acc = 100.0000%
Training Round 8: loss = 0.007410, time_cost = 0.0664 sec, acc = 100.0000%
Training Round 9: loss = 0.005025, time_cost = 0.0598 sec, acc = 100.0000%
Training Round 10: loss = 0.003536, time_cost = 0.0642 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 63.6000%, test_acc = 65.6000%
Training Round 11: loss = 0.002326, time_cost = 0.0602 sec, acc = 100.0000%
Training Round 12: loss = 0.001953, time_cost = 0.0699 sec, acc = 100.0000%
Training Round 13: loss = 0.001997, time_cost = 0.0800 sec, acc = 100.0000%
Training Round 14: loss = 0.002354, time_cost = 0.0700 sec, acc = 100.0000%
Training Round 15: loss = 0.003071, time_cost = 0.0704 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 66.6000%, test_acc = 68.4000%
Model: model_save/20220530_03_32_49.pth has been saved since it achieves higher validation accuracy.
Training Round 16: loss = 0.004266, time_cost = 0.0598 sec, acc = 100.0000%
Training Round 17: loss = 0.006087, time_cost = 0.0998 sec, acc = 100.0000%
Training Round 18: loss = 0.008686, time_cost = 0.0724 sec, acc = 100.0000%
Training Round 19: loss = 0.012164, time_cost = 0.0676 sec, acc = 100.0000%
Training Round 20: loss = 0.016671, time_cost = 0.0665 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 68.4000%, test_acc = 72.1000%
Model: model_save/20220530_03_32_49.pth has been saved since it achieves higher validation accuracy.
Training Round 21: loss = 0.022185, time_cost = 0.0700 sec, acc = 100.0000%
Training Round 22: loss = 0.028371, time_cost = 0.0799 sec, acc = 100.0000%
Training Round 23: loss = 0.034126, time_cost = 0.0603 sec, acc = 100.0000%
Training Round 24: loss = 0.038111, time_cost = 0.0701 sec, acc = 100.0000%
Training Round 25: loss = 0.039646, time_cost = 0.0698 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 73.4000%, test_acc = 75.3000%
Model: model_save/20220530_03_32_49.pth has been saved since it achieves higher validation accuracy.
Training Round 26: loss = 0.038864, time_cost = 0.0930 sec, acc = 100.0000%
Training Round 27: loss = 0.036258, time_cost = 0.0771 sec, acc = 100.0000%
Training Round 28: loss = 0.032562, time_cost = 0.0696 sec, acc = 100.0000%
Training Round 29: loss = 0.028673, time_cost = 0.1022 sec, acc = 100.0000%
Training Round 30: loss = 0.025110, time_cost = 0.0687 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 77.6000%, test_acc = 77.5000%
Model: model_save/20220530_03_32_49.pth has been saved since it achieves higher validation accuracy.
Training Round 31: loss = 0.022327, time_cost = 0.0714 sec, acc = 100.0000%
Training Round 32: loss = 0.020479, time_cost = 0.0687 sec, acc = 100.0000%
Training Round 33: loss = 0.019383, time_cost = 0.0571 sec, acc = 100.0000%
Training Round 34: loss = 0.018871, time_cost = 0.0897 sec, acc = 100.0000%
Training Round 35: loss = 0.018906, time_cost = 0.0663 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.2000%, test_acc = 76.9000%
Training Round 36: loss = 0.019282, time_cost = 0.0576 sec, acc = 100.0000%
Training Round 37: loss = 0.019764, time_cost = 0.0593 sec, acc = 100.0000%
Training Round 38: loss = 0.020300, time_cost = 0.0711 sec, acc = 100.0000%
Training Round 39: loss = 0.020948, time_cost = 0.0811 sec, acc = 100.0000%
Training Round 40: loss = 0.021613, time_cost = 0.0911 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.6000%, test_acc = 78.2000%
Training Round 41: loss = 0.022078, time_cost = 0.0598 sec, acc = 100.0000%
Training Round 42: loss = 0.022300, time_cost = 0.0782 sec, acc = 100.0000%
Training Round 43: loss = 0.022343, time_cost = 0.0648 sec, acc = 100.0000%
Training Round 44: loss = 0.022189, time_cost = 0.0797 sec, acc = 100.0000%
Training Round 45: loss = 0.021867, time_cost = 0.0693 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.8000%, test_acc = 76.8000%
Training Round 46: loss = 0.021415, time_cost = 0.0716 sec, acc = 100.0000%
Training Round 47: loss = 0.020892, time_cost = 0.0793 sec, acc = 100.0000%
Training Round 48: loss = 0.020376, time_cost = 0.0578 sec, acc = 100.0000%
Training Round 49: loss = 0.019925, time_cost = 0.0561 sec, acc = 100.0000%
Training Round 50: loss = 0.019554, time_cost = 0.0768 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.8000%, test_acc = 78.1000%
Training Round 51: loss = 0.019293, time_cost = 0.0626 sec, acc = 100.0000%
Training Round 52: loss = 0.019161, time_cost = 0.0635 sec, acc = 100.0000%
Training Round 53: loss = 0.019150, time_cost = 0.0650 sec, acc = 100.0000%
Training Round 54: loss = 0.019195, time_cost = 0.0648 sec, acc = 100.0000%
Training Round 55: loss = 0.019234, time_cost = 0.0624 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.0000%, test_acc = 77.6000%
Training Round 56: loss = 0.019226, time_cost = 0.0622 sec, acc = 100.0000%
Training Round 57: loss = 0.019170, time_cost = 0.0661 sec, acc = 100.0000%
Training Round 58: loss = 0.019055, time_cost = 0.0692 sec, acc = 100.0000%
Training Round 59: loss = 0.018897, time_cost = 0.0751 sec, acc = 100.0000%
Training Round 60: loss = 0.018725, time_cost = 0.0723 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.4000%, test_acc = 77.4000%
Training Round 61: loss = 0.018556, time_cost = 0.0685 sec, acc = 100.0000%
Training Round 62: loss = 0.018385, time_cost = 0.0702 sec, acc = 100.0000%
Training Round 63: loss = 0.018234, time_cost = 0.0740 sec, acc = 100.0000%
Training Round 64: loss = 0.018111, time_cost = 0.0674 sec, acc = 100.0000%
Training Round 65: loss = 0.018001, time_cost = 0.0778 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.0000%, test_acc = 77.7000%
Training Round 66: loss = 0.017905, time_cost = 0.0882 sec, acc = 100.0000%
Training Round 67: loss = 0.017838, time_cost = 0.0912 sec, acc = 100.0000%
Training Round 68: loss = 0.017777, time_cost = 0.0715 sec, acc = 100.0000%
Training Round 69: loss = 0.017707, time_cost = 0.0825 sec, acc = 100.0000%
Training Round 70: loss = 0.017605, time_cost = 0.0835 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 75.8000%, test_acc = 77.5000%
Training Round 71: loss = 0.017478, time_cost = 0.0817 sec, acc = 100.0000%
Training Round 72: loss = 0.017353, time_cost = 0.0746 sec, acc = 100.0000%
Training Round 73: loss = 0.017238, time_cost = 0.0816 sec, acc = 100.0000%
Training Round 74: loss = 0.017137, time_cost = 0.0913 sec, acc = 100.0000%
Training Round 75: loss = 0.017055, time_cost = 0.0872 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 76.0000%, test_acc = 77.6000%
> Training finished.

> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: both
> num_nodes: 2708, num_edges: [10556]
> num_feats: 1433, num_classes: 7
> num_samples: training = 140, validation = 500, test = 1000
> train_set_imbalance: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20}
> Loading model_save/20220530_03_32_49.pth
> Model Structure:
GCN(
  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)
  (embed_fc): Linear(in_features=128, out_features=128, bias=False)
  (layers): ModuleList(
    (0): ModuleList(
      (0): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
      (1): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
    )
  )
  (tran_fc): Linear(in_features=256, out_features=7, bias=True)
)
> Model sent to cuda:0
> Evaluation Results: valid_acc = 76.6000%, test_acc = 77.8000%
> Evaluation finished.
