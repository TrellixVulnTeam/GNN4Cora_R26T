> Seed: 6666666
> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: cited
> num_nodes: 2708, num_edges: [5429]
> num_feats: 1433, num_classes: 7
> num_samples: training = 270, validation = 812, test = 1626
> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}
> Initializing the Training Model: GCN
> Model Structure:
GCN(
  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)
  (embed_fc): Linear(in_features=128, out_features=128, bias=False)
  (layers): ModuleList(
    (0): ModuleList(
      (0): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
      (1): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
    )
  )
  (tran_fc): Linear(in_features=256, out_features=7, bias=True)
)
> Model sent to cuda:0
> Constructing the Optimizer: ADAM
> Using CrossEntropyLoss as the Loss Function.

learning_rate = 0.01, epochs = 75
eval_freq = 5, optimizer = ADAM

Start Training!
------------------------------------------------------------------------
Training Round 1: loss = 2.244957, time_cost = 1.4245 sec, acc = 6.6667%
Training Round 2: loss = 1.276673, time_cost = 0.0547 sec, acc = 52.2222%
Training Round 3: loss = 0.619382, time_cost = 0.0900 sec, acc = 91.1111%
Training Round 4: loss = 0.326834, time_cost = 0.0600 sec, acc = 98.8889%
Training Round 5: loss = 0.186004, time_cost = 0.0599 sec, acc = 99.2593%
!!! Evaluation: valid_acc = 67.9803%, test_acc = 71.0332%
Training Round 6: loss = 0.126278, time_cost = 0.0605 sec, acc = 98.8889%
Training Round 7: loss = 0.082933, time_cost = 0.0640 sec, acc = 99.6296%
Training Round 8: loss = 0.055020, time_cost = 0.0556 sec, acc = 99.6296%
Training Round 9: loss = 0.039385, time_cost = 0.0621 sec, acc = 100.0000%
Training Round 10: loss = 0.030077, time_cost = 0.0630 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 71.4286%, test_acc = 72.2017%
Training Round 11: loss = 0.024384, time_cost = 0.0599 sec, acc = 100.0000%
Training Round 12: loss = 0.020954, time_cost = 0.0598 sec, acc = 100.0000%
Training Round 13: loss = 0.019169, time_cost = 0.0551 sec, acc = 100.0000%
Training Round 14: loss = 0.018712, time_cost = 0.0703 sec, acc = 100.0000%
Training Round 15: loss = 0.019418, time_cost = 0.0602 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 72.9064%, test_acc = 73.8007%
Model: model_save/20220530_03_41_27.pth has been saved since it achieves higher validation accuracy.
Training Round 16: loss = 0.021303, time_cost = 0.0623 sec, acc = 100.0000%
Training Round 17: loss = 0.024448, time_cost = 0.0668 sec, acc = 100.0000%
Training Round 18: loss = 0.028789, time_cost = 0.0602 sec, acc = 100.0000%
Training Round 19: loss = 0.034155, time_cost = 0.0598 sec, acc = 100.0000%
Training Round 20: loss = 0.040249, time_cost = 0.0603 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 72.1675%, test_acc = 73.1857%
Training Round 21: loss = 0.046687, time_cost = 0.0546 sec, acc = 100.0000%
Training Round 22: loss = 0.052913, time_cost = 0.0712 sec, acc = 100.0000%
Training Round 23: loss = 0.058305, time_cost = 0.0671 sec, acc = 100.0000%
Training Round 24: loss = 0.062116, time_cost = 0.0618 sec, acc = 100.0000%
Training Round 25: loss = 0.063793, time_cost = 0.0598 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.8128%, test_acc = 72.3247%
Training Round 26: loss = 0.063271, time_cost = 0.0602 sec, acc = 100.0000%
Training Round 27: loss = 0.060995, time_cost = 0.0641 sec, acc = 100.0000%
Training Round 28: loss = 0.057588, time_cost = 0.0611 sec, acc = 100.0000%
Training Round 29: loss = 0.053833, time_cost = 0.0543 sec, acc = 100.0000%
Training Round 30: loss = 0.050075, time_cost = 0.0600 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.3202%, test_acc = 72.5707%
Training Round 31: loss = 0.046388, time_cost = 0.0500 sec, acc = 100.0000%
Training Round 32: loss = 0.043280, time_cost = 0.0700 sec, acc = 100.0000%
Training Round 33: loss = 0.041062, time_cost = 0.0600 sec, acc = 100.0000%
Training Round 34: loss = 0.039457, time_cost = 0.0604 sec, acc = 100.0000%
Training Round 35: loss = 0.038382, time_cost = 0.0596 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.4434%, test_acc = 71.7712%
Training Round 36: loss = 0.037994, time_cost = 0.0603 sec, acc = 100.0000%
Training Round 37: loss = 0.038142, time_cost = 0.0632 sec, acc = 100.0000%
Training Round 38: loss = 0.038551, time_cost = 0.0766 sec, acc = 100.0000%
Training Round 39: loss = 0.039220, time_cost = 0.0500 sec, acc = 100.0000%
Training Round 40: loss = 0.040012, time_cost = 0.0740 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.0739%, test_acc = 72.0787%
Training Round 41: loss = 0.040766, time_cost = 0.0612 sec, acc = 100.0000%
Training Round 42: loss = 0.041414, time_cost = 0.0586 sec, acc = 100.0000%
Training Round 43: loss = 0.041794, time_cost = 0.0549 sec, acc = 100.0000%
Training Round 44: loss = 0.041834, time_cost = 0.0603 sec, acc = 100.0000%
Training Round 45: loss = 0.041654, time_cost = 0.0649 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 69.9507%, test_acc = 72.2017%
Training Round 46: loss = 0.041263, time_cost = 0.0606 sec, acc = 100.0000%
Training Round 47: loss = 0.040651, time_cost = 0.0692 sec, acc = 100.0000%
Training Round 48: loss = 0.039933, time_cost = 0.0602 sec, acc = 100.0000%
Training Round 49: loss = 0.039199, time_cost = 0.0633 sec, acc = 100.0000%
Training Round 50: loss = 0.038449, time_cost = 0.0601 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 69.8276%, test_acc = 71.5867%
Training Round 51: loss = 0.037787, time_cost = 0.0692 sec, acc = 100.0000%
Training Round 52: loss = 0.037257, time_cost = 0.0652 sec, acc = 100.0000%
Training Round 53: loss = 0.036838, time_cost = 0.0647 sec, acc = 100.0000%
Training Round 54: loss = 0.036524, time_cost = 0.0599 sec, acc = 100.0000%
Training Round 55: loss = 0.036299, time_cost = 0.0603 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.1970%, test_acc = 71.4637%
Training Round 56: loss = 0.036146, time_cost = 0.0596 sec, acc = 100.0000%
Training Round 57: loss = 0.036074, time_cost = 0.0651 sec, acc = 100.0000%
Training Round 58: loss = 0.036026, time_cost = 0.0586 sec, acc = 100.0000%
Training Round 59: loss = 0.035979, time_cost = 0.0585 sec, acc = 100.0000%
Training Round 60: loss = 0.035909, time_cost = 0.0660 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 70.1970%, test_acc = 71.7097%
Training Round 61: loss = 0.035793, time_cost = 0.0596 sec, acc = 100.0000%
Training Round 62: loss = 0.035609, time_cost = 0.0602 sec, acc = 100.0000%
Training Round 63: loss = 0.035371, time_cost = 0.0680 sec, acc = 100.0000%
Training Round 64: loss = 0.035083, time_cost = 0.0634 sec, acc = 100.0000%
Training Round 65: loss = 0.034755, time_cost = 0.0586 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 69.8276%, test_acc = 71.7712%
Training Round 66: loss = 0.034422, time_cost = 0.0821 sec, acc = 100.0000%
Training Round 67: loss = 0.034097, time_cost = 0.0662 sec, acc = 100.0000%
Training Round 68: loss = 0.033791, time_cost = 0.0615 sec, acc = 100.0000%
Training Round 69: loss = 0.033525, time_cost = 0.0701 sec, acc = 100.0000%
Training Round 70: loss = 0.033303, time_cost = 0.0601 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 68.9655%, test_acc = 71.5252%
Training Round 71: loss = 0.033105, time_cost = 0.0701 sec, acc = 100.0000%
Training Round 72: loss = 0.032939, time_cost = 0.0597 sec, acc = 100.0000%
Training Round 73: loss = 0.032788, time_cost = 0.0652 sec, acc = 100.0000%
Training Round 74: loss = 0.032646, time_cost = 0.0516 sec, acc = 100.0000%
Training Round 75: loss = 0.032509, time_cost = 0.0498 sec, acc = 100.0000%
!!! Evaluation: valid_acc = 68.9655%, test_acc = 71.2792%
> Training finished.

> device: cuda:0
> Loading DataSet from data/cora/
> Data sent to cuda:0
> view: cited
> num_nodes: 2708, num_edges: [5429]
> num_feats: 1433, num_classes: 7
> num_samples: training = 270, validation = 812, test = 1626
> train_set_imbalance: {0: 28, 1: 35, 2: 79, 3: 50, 4: 22, 5: 20, 6: 36}
> Loading model_save/20220530_03_41_27.pth
> Model Structure:
GCN(
  (proj_fc): Linear(in_features=1433, out_features=128, bias=False)
  (embed_fc): Linear(in_features=128, out_features=128, bias=False)
  (layers): ModuleList(
    (0): ModuleList(
      (0): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
      (1): MultiHeadCGaANLayer(
        (cGaANs): ModuleList(
          (0): CGaANLayer()
        )
      )
    )
  )
  (tran_fc): Linear(in_features=256, out_features=7, bias=True)
)
> Model sent to cuda:0
> Evaluation Results: valid_acc = 72.9064%, test_acc = 73.4317%
> Evaluation finished.
